{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f144287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import silhouette_score\n",
    "import pandas as pd \n",
    "import torch.optim as optim\n",
    "from braingeneers.analysis import SpikeData\n",
    "import os\n",
    "import json\n",
    "import pytorch_lightning as pl\n",
    "from backbones import ResNet18Enc, ResNet18Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb4935",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "waveform_files = [\"data/\" + f for f in os.listdir(\"./data\") if f.endswith('.npy')]\n",
    "meta_files = [f.replace('.npy', '.json') for f in waveform_files]\n",
    "\n",
    "waveforms = []\n",
    "isi_dist = []\n",
    "\n",
    "for wf, mf in zip(waveform_files, meta_files):\n",
    "    waveforms.append(np.load(wf))\n",
    "    \n",
    "    with open(mf, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    sd = SpikeData([json_data[key]['train'] for key in json_data.keys()])\n",
    "    trains = sd.train\n",
    "\n",
    "    all_isi = sd.interspike_intervals()\n",
    "    \n",
    "    for isi in all_isi:\n",
    "        hist, edges = np.histogram(isi, bins=50, density=True)\n",
    "        isi_dist.append(hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd68df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = np.concatenate(waveforms, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e071f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "isi_dist[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98157c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EphysDataset(Dataset):\n",
    "    def __init__(self, waveforms, isi_dists, normalize=True):\n",
    "        self.waveforms = np.array(waveforms)\n",
    "        self.isi_dists = np.array(isi_dists)\n",
    "        \n",
    "        assert len(self.waveforms) == len(self.isi_dists)\n",
    "        self.normalize = normalize\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        waveform = torch.as_tensor(self.waveforms[idx, ...]).float()\n",
    "        isi_dist = torch.as_tensor(self.isi_dists[idx, ...]).float()\n",
    "        \n",
    "        if self.normalize:\n",
    "            waveform = (waveform - waveform.mean()) / waveform.std()\n",
    "#             isi_dist = (isi_dist - isi_dist.mean()) / isi_dist.std()\n",
    "\n",
    "        return waveform.unsqueeze(0), isi_dist.unsqueeze(0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.waveforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c850dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, batch_size, temperature=0.5):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.register_buffer(\"temperature\", torch.tensor(temperature))\n",
    "        self.register_buffer(\"negatives_mask\", (~torch.eye(batch_size * 2, batch_size * 2, dtype=bool)).float())\n",
    "            \n",
    "    def forward(self, emb_i, emb_j):\n",
    "        \"\"\"\n",
    "        emb_i and emb_j are batches of embeddings, where corresponding indices are pairs\n",
    "        z_i, z_j as per SimCLR paper\n",
    "        \"\"\"\n",
    "        z_i = F.normalize(emb_i, dim=1)\n",
    "        z_j = F.normalize(emb_j, dim=1)\n",
    "\n",
    "        representations = torch.cat([z_i, z_j], dim=0)\n",
    "        similarity_matrix = F.cosine_similarity(representations.unsqueeze(1), representations.unsqueeze(0), dim=2)\n",
    "        \n",
    "        sim_ij = torch.diag(similarity_matrix, self.batch_size)\n",
    "        sim_ji = torch.diag(similarity_matrix, -self.batch_size)\n",
    "        positives = torch.cat([sim_ij, sim_ji], dim=0)\n",
    "\n",
    "        nominator = torch.exp(positives / self.temperature)\n",
    "        denominator = self.negatives_mask * torch.exp(similarity_matrix / self.temperature)\n",
    "\n",
    "        loss_partial = -torch.log(nominator / torch.sum(denominator, dim=1))\n",
    "        loss = torch.sum(loss_partial) / (2 * self.batch_size)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6729a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixedModel(nn.Module):\n",
    "    def __init__(self, encoder=None, decoder=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        if encoder is not None:\n",
    "            self.encoder = encoder\n",
    "        \n",
    "        self.fc_wave = nn.Linear(16*(4), 16)\n",
    "        self.fc_time = nn.Linear(16*(4), 16)\n",
    "        \n",
    "        self.norm1 = nn.BatchNorm1d(16)\n",
    "        \n",
    "        self.wave_upsample = nn.Linear(16, 16*(4))\n",
    "        self.time_upsample = nn.Linear(16, 16*(4))\n",
    "        \n",
    "        self.norm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        if decoder is not None:\n",
    "            self.decoder = decoder\n",
    "        \n",
    "    def forward(self, wave, time):\n",
    "        # encoder zone \n",
    "#         rep_w, rep_t = self.encoder(wave), self.encoder(time)\n",
    "#         rep_w, rep_t = self.attn_enc(rep_w), self.attn_enc(rep_t)\n",
    "#         B, C, H = rep_w.shape\n",
    "        \n",
    "#         # middle zone \n",
    "#         rep_w, rep_t = rep_w.view(B, -1), rep_t.view(B, -1)\n",
    "#         rep_w, rep_t = self.fc_wave(rep_w), self.fc_time(rep_t)\n",
    "#         rep_w, rep_t = self.norm1(rep_w), self.norm1(rep_t)\n",
    "        \n",
    "#         # decoder zone \n",
    "#         decode_w, decode_t = self.wave_upsample(rep_w), self.time_upsample(rep_t)\n",
    "#         decode_w, decode_t = self.norm2(decode_w), self.norm2(decode_t)\n",
    "#         decode_w, decode_t = decode_w.view(B, C, -1), decode_t.view(B, C, -1)\n",
    "#         decode_w, decode_t = self.attn_dec(decode_w), self.attn_dec(decode_t)\n",
    "#         decode_w, decode_t = self.decoder(decode_w), self.decoder(decode_t)\n",
    "        e_wave, e_time = self.encoder(wave), self.encoder(time)\n",
    "        d_wave, d_time = self.decoder(e_wave), self.decoder(e_time)\n",
    "        \n",
    "        decode_w, decode_t = F.interpolate(d_wave, (wave.size(-1),)), F.interpolate(d_time, (time.size(-1),))\n",
    "\n",
    "        return e_wave, e_time, decode_w, decode_t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bfe16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2344da8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = MixedModel(\n",
    "    encoder=ResNet18Enc(z_dim=5),\n",
    "    decoder=ResNet18Dec(z_dim=5)\n",
    ")\n",
    "\n",
    "sample = torch.randn(2, 8, 1, 50).unbind(0)\n",
    "\n",
    "x,y,z,w = model(*sample)\n",
    "x.shape, y.shape, z.shape, w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa90e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.utilities import grad_norm\n",
    "\n",
    "class MultimodalEmbedding(pl.LightningModule):\n",
    "    def __init__(self, base_model, batch_size, contrastive_loss_weight=1.0):\n",
    "        super().__init__()\n",
    "        self.model = base_model\n",
    "        self.contrastive_loss_weight = contrastive_loss_weight\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        self.contrastive_loss = ContrastiveLoss(batch_size, temperature=0.5)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        wave, time = batch\n",
    "        rep_w, rep_t, decode_w, decode_t = self.model(wave, time)\n",
    "\n",
    "        mse_loss_w = self.mse_loss(decode_w, wave)\n",
    "        mse_loss_t = self.mse_loss(decode_t, time)\n",
    "        mse_loss = mse_loss_w + mse_loss_t\n",
    "\n",
    "        emb_i, emb_j = rep_w, rep_t\n",
    "        contrastive_loss = self.contrastive_loss(emb_i, emb_j)\n",
    "\n",
    "        # Combine losses\n",
    "        total_loss = mse_loss + self.contrastive_loss_weight * contrastive_loss\n",
    "\n",
    "        self.log('train_loss', total_loss)\n",
    "        self.log('train_mse_loss', mse_loss)\n",
    "        self.log('train_xe_loss', contrastive_loss)\n",
    "        \n",
    "        norms = grad_norm(self.model.encoder, norm_type=2)\n",
    "        self.log_dict(norms)\n",
    "        norms = grad_norm(self.model.decoder, norm_type=2)\n",
    "        self.log_dict(norms)\n",
    "        norms = grad_norm(self.model.fc_wave, norm_type=2)\n",
    "        self.log_dict(norms)\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        wave, time = batch\n",
    "        rep_w, rep_t, decode_w, decode_t = self.model(wave, time)\n",
    "\n",
    "        mse_loss_w = self.mse_loss(decode_w, wave)\n",
    "        mse_loss_t = self.mse_loss(decode_t, time)\n",
    "        mse_loss = mse_loss_w + mse_loss_t\n",
    "\n",
    "        emb_i, emb_j = rep_w, rep_t\n",
    "        contrastive_loss = self.contrastive_loss(emb_i, emb_j)\n",
    "\n",
    "        # Combine losses\n",
    "        total_loss = mse_loss + self.contrastive_loss_weight * contrastive_loss\n",
    "\n",
    "        self.log('val_loss', total_loss)\n",
    "        self.log('val_mse_loss', mse_loss)\n",
    "        self.log('val_xe_loss', contrastive_loss)\n",
    "\n",
    "        return total_loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa3802a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(reinit=True)\n",
    "bs = 512\n",
    "wf_train, isi_train = waveforms[:15000], isi_dist[:15000]\n",
    "wf_val, isi_val = waveforms[15000:], isi_dist[15000:]\n",
    "\n",
    "traindata = EphysDataset(wf_train, isi_train)\n",
    "valdata = EphysDataset(wf_val, isi_val)\n",
    "\n",
    "train_loader = DataLoader(traindata, batch_size=bs, drop_last=True)\n",
    "val_loader = DataLoader(valdata, batch_size=bs, drop_last=True)\n",
    "\n",
    "base_model = MixedModel()\n",
    "model = MultimodalEmbedding(base_model=base_model, batch_size=bs, contrastive_loss_weight=0.5)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=pl.loggers.WandbLogger(),\n",
    "#     limit_train_batches=1,\n",
    "    log_every_n_steps=5,\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6561c57a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a793cd66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be51a9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "braingeneers",
   "language": "python",
   "name": "braingeneers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
